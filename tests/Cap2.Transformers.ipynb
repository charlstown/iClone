{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "aa712817c06a4c1ab2415009e7b8ccca",
    "deepnote_cell_type": "code",
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 2323,
    "execution_start": 1744294397965,
    "source_hash": "4ac47053"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\slope\\anaconda3BIS\\envs\\AIGen\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\slope\\anaconda3BIS\\envs\\AIGen\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\slope\\.cache\\huggingface\\hub\\models--Qwen--Qwen2-0.5B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2132, 572, 264, 6319, 323, 13458, 88, 1899, 304, 279]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Use the id of the model you want to use\n",
    "# GPT-2 \"openai-community/gpt2\"\n",
    "# Qwen \"Qwen/Qwen2-0.5B\"\n",
    "# SmolLM \"HuggingFaceTB/SmolLM-135M\"\n",
    "\n",
    "prompt = \"It was a dark and stormy day in the\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "input_ids = tokenizer(prompt).input_ids\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "a58c5c0b1d3c47a09fcb7f18e9ab7ca1",
    "deepnote_cell_type": "code",
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 0,
    "execution_start": 1744294400335,
    "source_hash": "f1658017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2132 \t: It\n",
      "572 \t:  was\n",
      "264 \t:  a\n",
      "6319 \t:  dark\n",
      "323 \t:  and\n",
      "13458 \t:  storm\n",
      "88 \t: y\n",
      "1899 \t:  day\n",
      "304 \t:  in\n",
      "279 \t:  the\n"
     ]
    }
   ],
   "source": [
    "for t in input_ids:\n",
    "    print(t, \"\\t:\", tokenizer.decode(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "8bcb1634bb8544db97512f2b44aee8ce",
    "deepnote_cell_type": "code",
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 1545,
    "execution_start": 1744294400395,
    "source_hash": "f4ebe967"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "624d6ba08f0e4bedb94bc48cef14efe3",
    "deepnote_cell_type": "code",
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 264,
    "execution_start": 1744294401995,
    "source_hash": "14e287ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 151936])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model(input_ids)\n",
    "outputs.logits.shape  # An output for each input token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "9fb7886a1a444cee869f656a5856f94a",
    "deepnote_cell_type": "code",
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 344,
    "execution_start": 1744294402305,
    "source_hash": "319bdac4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3283)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logits = model(input_ids).logits[0, -1]  # The last set of logits\n",
    "final_logits.argmax()  # The position of the maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "43f8e0f807b94e7d8ff9ac949ef3fdf4",
    "deepnote_cell_type": "code",
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 100,
    "execution_start": 1744294402695,
    "source_hash": "388c212c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m top10 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtopk(final_logits\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value, index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(top10\u001b[38;5;241m.\u001b[39mvalues, top10\u001b[38;5;241m.\u001b[39mindices):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer\u001b[38;5;241m.\u001b[39mdecode(index)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "top10 = torch.topk(final_logits.softmax(dim=0), 10)\n",
    "for value, index in zip(top10.values, top10.indices):\n",
    "    print(f\"{tokenizer.decode(index):<10} {value.item():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "e4c7cc2c08164d88abe043699cd5cec9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "2021132c-0a28-46ad-b1b8-6906f3e4f496",
    "execution_millis": 179114,
    "execution_start": 1744205512223,
    "source_hash": "259d011c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "ename": "KernelInterrupted",
     "evalue": "Execution interrupted by the Jupyter kernel.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."
     ]
    }
   ],
   "source": [
    "output_ids = model.generate(input_ids, max_new_tokens=20)\n",
    "decoded_text = tokenizer.decode(output_ids[0])\n",
    "\n",
    "print(\"Input IDs\", input_ids[0])\n",
    "print(\"Output IDs\", output_ids)\n",
    "print(f\"Generated text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "223e1b323a93445f94d6608bde1893e7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true
   },
   "outputs": [],
   "source": [
    "beam_output = model.generate(\n",
    "    input_ids,\n",
    "    num_beams=5,\n",
    "    repetition_penalty=2.0,\n",
    "    max_new_tokens=38,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(beam_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3c1c36e5237b44fca37554a12dc38ca6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true
   },
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "# Setting the seed ensures we get the same results every time we run this code\n",
    "set_seed(70)\n",
    "\n",
    "sampling_output = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=3.0,\n",
    "    max_new_tokens=40,\n",
    "    top_k=0,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cell_id": "126685aa4ac54cd8992252fbac35b17c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "f13d1d23-5455-4d8d-958f-41adff579af8",
    "execution_millis": 275,
    "execution_start": 1744274103339,
    "source_hash": "5cefbc31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[785, 15494, 374, 279, 8679, 315, 1657]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Use the id of the model you want to use\n",
    "# GPT-2 \"openai-community/gpt2\"\n",
    "# Qwen \"Qwen/Qwen2-0.5B\"\n",
    "# SmolLM \"HuggingFaceTB/SmolLM-135M\"\n",
    "\n",
    "prompt = \"The universe is the fear of many\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "input_ids = tokenizer(prompt).input_ids\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cell_id": "083c8fde1dfa44b3b6579767e9f9b74d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "f13d1d23-5455-4d8d-958f-41adff579af8",
    "execution_millis": 4182,
    "execution_start": 1744274105933,
    "source_hash": "f4ebe967"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "cell_id": "8589d223f7694486a9910ee697a13361",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "f13d1d23-5455-4d8d-958f-41adff579af8",
    "execution_millis": 39416,
    "execution_start": 1744274112598,
    "source_hash": "6ead56dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 151936])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We tokenize again but specifying the tokenizer that we want it to\n",
    "# return a PyTorch tensor, which is what the model expects,\n",
    "# rather than a list of integers\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model(input_ids)\n",
    "outputs.logits.shape  # An output for each input token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "cell_id": "7be1d46a130a49b19a610e5cd4664d07",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "f13d1d23-5455-4d8d-958f-41adff579af8",
    "execution_millis": 200919,
    "execution_start": 1744274152058,
    "source_hash": "2a54dfaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# The mistake in the code is that input_ids (of type tensor) is being used directly inside the generate function, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# but the input to model.generate requires it to be properly formatted for PyTorch.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Convert the input_ids (already a tensor from prompt tokenization) if needed to the correct format (like explicit batch size)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m input_ids_tensor \u001b[38;5;241m=\u001b[39m input_ids  \u001b[38;5;66;03m# Assuming input_ids is already a tensor from earlier steps\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m sampling_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mdecode(sampling_output[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/generation/utils.py:2463\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2455\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2456\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2457\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2458\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2459\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2460\u001b[0m     )\n\u001b[1;32m   2462\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2463\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2464\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2474\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2475\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2476\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2477\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2478\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2479\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2480\u001b[0m     )\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/generation/utils.py:3432\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3430\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3432\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3434\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3435\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3436\u001b[0m     outputs,\n\u001b[1;32m   3437\u001b[0m     model_kwargs,\n\u001b[1;32m   3438\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3439\u001b[0m )\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:823\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    819\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    820\u001b[0m )\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:549\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    538\u001b[0m         partial(decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs),\n\u001b[1;32m    539\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m         position_embeddings,\n\u001b[1;32m    547\u001b[0m     )\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:262\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:169\u001b[0m, in \u001b[0;36mQwen2Attention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    168\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m--> 169\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:93\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m     91\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m     92\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(q) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m---> 93\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:63\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     59\u001b[0m         down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrotate_half\u001b[39m(x):\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Rotates half the hidden dims of the input.\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# The mistake in the code is that input_ids (of type tensor) is being used directly inside the generate function, \n",
    "# but the input to model.generate requires it to be properly formatted for PyTorch.\n",
    "\n",
    "# Convert the input_ids (already a tensor from prompt tokenization) if needed to the correct format (like explicit batch size)\n",
    "input_ids_tensor = input_ids  # Assuming input_ids is already a tensor from earlier steps\n",
    "\n",
    "sampling_output = model.generate(\n",
    "    input_ids_tensor,\n",
    "    # Check the token IDs for the words ' positive' and ' negative'\n",
    "# (note the space before the words)\n",
    "tokenizer.encode(\" positive\"), tokenizer.encode(\" negative\")\n",
    "    do_sample=True,\n",
    "    temperature=3.0,\n",
    "    max_new_tokens=50,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d9bf1d4e1f384e7fb6386ccfcadaaff1",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7cef6dc2496145d094815b85a75c360d",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "14c4cf7cd3384c9e9071be930e813f8f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 59,
      "type": "marks"
     }
    ]
   },
   "source": [
    "Ejemplo paso a paso entendiendo los objetos que intervienen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cc9511ccff634ed0b85f34edb3b36768",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "61199fb1fcdc4f1289e8ac1f305ddd0c",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": "0cdca9dd58954044bd9776f81cc9eaa2",
    "deepnote_cell_type": "code",
    "execution_context_id": "3bdae8a3-ec66-435d-831e-407d96c85d0f",
    "execution_millis": 4360,
    "execution_start": 1744295399118,
    "source_hash": "5ff3c94e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 151643\n",
      "Dimensiones de los embeddings: 896\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "\n",
    "\n",
    "# Obtener dimensiones\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = model.config.hidden_size\n",
    "\n",
    "print(f\"Tamaño del vocabulario: {vocab_size}\")\n",
    "print(f\"Dimensiones de los embeddings: {embedding_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "4ad0b5f49ae04102b31094359fe27074",
    "deepnote_cell_type": "code",
    "execution_context_id": "3bdae8a3-ec66-435d-831e-407d96c85d0f",
    "execution_millis": 2,
    "execution_start": 1744294831006,
    "source_hash": "118b0a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   32, 50019,   374,   304,   279, 17951]])\n"
     ]
    }
   ],
   "source": [
    "#prompt = f\"\"\"Question: Is the following review positive or\n",
    "#negative about the movie?\n",
    "#Review: {review} Answer:\"\"\"\n",
    "\n",
    "prompt = \"A whale is in the ocean\"\n",
    "\n",
    "#Tokenizo el prompt y lo convierto en un tensor de pytorch\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "print(input_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "8851c1d68d15422daa2e4b99579c0259",
    "deepnote_cell_type": "code",
    "execution_context_id": "3bdae8a3-ec66-435d-831e-407d96c85d0f",
    "execution_millis": 221,
    "execution_start": 1744294833049,
    "source_hash": "b334e03e"
   },
   "outputs": [],
   "source": [
    "#model(input_ids): Esta línea pasa el tensor input_ids (que contiene los tokens del prompt) a través del modelo de lenguaje.\n",
    "#outputs: El resultado de esta operación es un objeto que contiene varias salidas del modelo, incluyendo los logits.\n",
    "outputs = model(input_ids)\n",
    "\n",
    "#!!!!!!\n",
    "#Logits: Para generar texto.\n",
    "#Hidden States:Cada token en la secuencia pasa por múltiples capas del modelo, y en cada capa, se generan representaciones internas\n",
    "# (hidden states) que capturan la información contextual. Estas representaciones se actualizan en cada capa, integrando información de todos los tokens anteriores.\n",
    "#Contexto Acumulado: Las representaciones internas de cada token contienen información acumulada del contexto general de la secuencia. Esto permite al modelo entender cómo cada palabra se relaciona con las demás en el contexto.\n",
    "#Attentions: Para entender la distribución de atención del modelo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "799f331366d64a45a801ff092209a21c",
    "deepnote_cell_type": "code",
    "execution_context_id": "3bdae8a3-ec66-435d-831e-407d96c85d0f",
    "execution_millis": 5,
    "execution_start": 1744294834502,
    "source_hash": "28f9f833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.7713,  2.5144,  1.7077,  ..., -5.7213, -5.7200, -5.7210],\n",
      "         [ 3.7050,  4.8398,  1.4650,  ..., -7.0109, -7.0087, -7.0092],\n",
      "         [ 3.5571,  3.2980, -0.5132,  ..., -6.1721, -6.1712, -6.1717],\n",
      "         [ 1.5985,  1.3557,  1.1875,  ..., -7.3146, -7.3138, -7.3154],\n",
      "         [ 3.7240,  0.7333,  0.0122,  ..., -6.0287, -6.0287, -6.0292],\n",
      "         [ 7.7887,  3.1480,  2.4267,  ..., -7.1898, -7.1884, -7.1901]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#logits: Valores sin normalizar que representan la \"confianza\" del modelo en \n",
    "#cada posible palabra siguiente en el vocabulario. Se utilizan para generar texto.\n",
    "logits = outputs.logits\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "db21cff3273247c1b333a360e0026747",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 3,
    "execution_start": 1744290939960,
    "source_hash": "dda319b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.8884,  4.8228,  0.7553,  ..., -5.6167, -5.6165, -5.6168],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "last_token_logits = logits[0, -1, :]\n",
    "print(last_token_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "4f2884556d494c8c98be0c197be842e9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 332,
    "execution_start": 1744290941954,
    "source_hash": "3b3b8071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.8884,  4.8228,  0.7553,  ..., -5.6167, -5.6165, -5.6168],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "final_logits = model(input_ids).logits[0, -1]\n",
    "print(final_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": "ae97b2b96f274e9b88ce7a9ad2914056",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 3,
    "execution_start": 1744290946634,
    "source_hash": "1a3281a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3354e-05, 1.2505e-05, 2.1411e-07,  ..., 3.6585e-10, 3.6594e-10,\n",
      "        3.6580e-10], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(final_logits.softmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": "1a1b75bb9b4a4f52b7c5603b7843dece",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 8,
    "execution_start": 1744290949251,
    "source_hash": "ebba486d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I         40.17%\n",
      " i         7.59%\n",
      " a         6.40%\n",
      " my        3.77%\n",
      " you       3.26%\n",
      " the       1.48%\n",
      " it        1.15%\n",
      " now       1.03%\n",
      " have      0.83%\n",
      " here      0.64%\n",
      " when      0.60%\n",
      " there     0.59%\n",
      " love      0.59%\n",
      " don       0.58%\n",
      " can       0.56%\n",
      " this      0.56%\n",
      " not       0.53%\n",
      " they      0.52%\n",
      " want      0.51%\n",
      " always    0.49%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "top10 = torch.topk(final_logits.softmax(dim=0), 20)\n",
    "for value, index in zip(top10.values, top10.indices):\n",
    "    print(f\"{tokenizer.decode(index):<10} {value.item():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_id": "6ab94e88a8244c34a9d1c93b27805b82",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 12499,
    "execution_start": 1744291246436,
    "source_hash": "17c93867"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "I'm a sexy zebra and love to fuck\n",
      "Bunny and Muppet do fuck stuff again but you will be bored, It says i know if there something or someone new please let us know.. Reply -1 Posted: -59. Posted:: Reply x860 | November | No\n",
      "Please see \"Hot Zephyrs\n",
      "Fucks me. And my dick. I love cock every night. Come near if i'm a slut or your gonna love what I have\n",
      "No fucking shame\n",
      "Posted\n",
      "I fuck\n"
     ]
    }
   ],
   "source": [
    "sampling_output = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=2.5,\n",
    "    max_new_tokens=100,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cell_id": "d8c977b2f88c49cdb9dd7f45f01765ea",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 11916,
    "execution_start": 1744291445475,
    "source_hash": "810aab18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "I'm a sexy zebra and I'm free in the city. A free zebra, I don't have any rules. I'd prefer a sexy friend or a pretty lady. My job is to bring you pleasure but it is up to you to enjoy the show and give them what I want. My free sexy zebra is ready to give you a treat with me. I'm always ready to show you what I can do in the bed. I'm a pussy zebra that wants you to feel like a sex bomb.\n"
     ]
    }
   ],
   "source": [
    "sampling_output = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_new_tokens=100,\n",
    "    top_k=40,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2e167cce4867436a99f1d16e5db495b9",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "87ec30ca7be844a2be8e9d9cea89a095",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d856a6425c54433e8a4f31fda938b5cd",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 24,
      "type": "marks"
     }
    ]
   },
   "source": [
    "Zero-Shot Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bb394044985948fa923ea61c649ff40a",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7c9fa8ca6d6a4026a8b72f9549cae42a",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "8ca82cc6d3da4777b4b00647d0f42836",
    "deepnote_cell_type": "code",
    "execution_context_id": "c2e61181-37df-4a58-8c80-e5439fbf2f97",
    "execution_millis": 13064,
    "execution_start": 1744361721970,
    "source_hash": "df14b416"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "0b096dcd3c0d4cd4adebadf0147e317a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 0,
    "execution_start": 1744293062775,
    "source_hash": "7ff3c85d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([30487], [42224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the token IDs for the words ' positive' and ' negative'\n",
    "# (note the space before the words)\n",
    "tokenizer.encode(\"positive\"), tokenizer.encode(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "194e610bec68478ca51058c7c756912f",
    "deepnote_cell_type": "code",
    "execution_context_id": "c2e61181-37df-4a58-8c80-e5439fbf2f97",
    "execution_millis": 1,
    "execution_start": 1744361735080,
    "source_hash": "f484df19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   40,  2776,   264, 10886,  1147, 50213,   323,   358,  1075,   432,\n",
      "            13]])\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I'm a sexy zebra and I like it.\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "76e23f7ac6444b5ba75bcfe87edba9cf",
    "deepnote_cell_type": "code",
    "execution_context_id": "c2e61181-37df-4a58-8c80-e5439fbf2f97",
    "execution_millis": 774,
    "execution_start": 1744362914461,
    "source_hash": "da5635f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.5712, -0.8256,  1.7369,  ..., -5.0794, -5.0806, -5.0801],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(input_ids)\n",
    "logits = outputs.logits\n",
    "final_logits = model(input_ids).logits[0, -1]\n",
    "print(final_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": "f2d15ab4a30b4ef9ac470607f1850e04",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 1,
    "execution_start": 1744293150982,
    "source_hash": "1d83a712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8275, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#cercanía a _positive_\n",
    "print(final_logits[6785])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "b994fbfa9f2a4cc687cd2176f1930569",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 3,
    "execution_start": 1744293152254,
    "source_hash": "1796701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2383, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#cercanía a _negative_\n",
    "print(final_logits[8225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "d021d5b2c03a4fc889e4a54af0403ef8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 0,
    "execution_start": 1744293205975,
    "source_hash": "4feb357d"
   },
   "outputs": [],
   "source": [
    "def score(review):\n",
    "    \"\"\"Predict whether it is positive or negative\n",
    "\n",
    "    This function predicts whether a review is positive or negative\n",
    "    using a bit of clever prompting. It looks at the logits for the\n",
    "    tokens ' positive' and ' negative', and returns the label\n",
    "    with the highest score.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Question: Is the following review positive or\n",
    "negative about the movie?\n",
    "Review: {review} Answer:\"\"\"\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    final_logits = model(input_ids).logits[0, -1]\n",
    "    if final_logits[6785] > final_logits[8225]:\n",
    "        print(\"Positive\")\n",
    "    else:\n",
    "        print(\"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": "7994f0ea55bf4d698be891a65ef88ef8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 412,
    "execution_start": 1744293253679,
    "source_hash": "71091003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "score(\"It was a so crazy and good time movie..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2a6e648755da407eb89ee732321ca2b4",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "24cb91faca0c4f4582d9ef02a5ac6e66",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 23,
      "type": "marks"
     }
    ]
   },
   "source": [
    "Few-shot Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "43078ff037da4d3ea715dfb6922282ec",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": "76f54f2793ad4df1b47ba1d1005c34ad",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_context_id": "8a5a1072-a689-4f31-b90b-eb4c4abf1ca0",
    "execution_millis": 3992,
    "execution_start": 1744293508335,
    "source_hash": "b44c8ca1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Què te parece este texto?\n",
      "\n",
      "English: I do not speak Spanish.\n",
      "Spanish: No hablo español.\n",
      "\n",
      "English: See you later!\n",
      "Spanish: ¡Hasta luego!\n",
      "\n",
      "English: Where is a good restaurant?\n",
      "Spanish: ¿Dónde hay un buen restaurante?\n",
      "\n",
      "English: What rooms do you have available?\n",
      "Spanish: ¿Qué habitaciones tiene disponibles?\n",
      "\n",
      "English: I like soccer\n",
      "Spanish: Me gusta el fútbol\n",
      "\n",
      "English: What is your favorite color?\n",
      "Spanish: ¿Qué es tu color favorito?\n",
      "\n",
      "English: What is\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\\\n",
    "Traduce al español:\n",
    "\n",
    "English: I do not speak Spanish.\n",
    "Spanish: No hablo español.\n",
    "\n",
    "English: See you later!\n",
    "Spanish: ¡Hasta luego!\n",
    "\n",
    "English: Where is a good restaurant?\n",
    "Spanish: ¿Dónde hay un buen restaurante?\n",
    "\n",
    "English: What rooms do you have available?\n",
    "Spanish: ¿Qué habitaciones tiene disponibles?\n",
    "\n",
    "English: I like soccer\n",
    "Spanish:\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "output = model.generate(\n",
    "    inputs,\n",
    "    max_new_tokens=30,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "58c91d38699b49bc8ca4aaf66d201186",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ab4e3139094e47d5b036269dfa2019e7",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c19d40cbc556432f886a8f1e46c5cd86",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 50,
      "type": "marks"
     }
    ]
   },
   "source": [
    "Sequence-to-Sequence Tasks, Encoder-decoder models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "627ac6c8d9cf45be9e010edb711c8ad0",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e9813da41d884050aa4588c1296d9c2f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Between encoder-only, decoder-only, and encoder-decoder models, companies and research labs have released a large number of new open and closed language models, such as GPT-4, Mistral, Falcon, Llama, Qwen, Yi, Claude, Bloom, Gemma, and hundreds more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "120009624a8746cdbeb2cc0260da805b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 0,
      "type": "marks"
     }
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "cb44bfa8b56448a9a1835e08718889e3",
    "deepnote_cell_type": "code",
    "execution_context_id": "c2e61181-37df-4a58-8c80-e5439fbf2f97",
    "execution_millis": 789,
    "execution_start": 1744363126645,
    "source_hash": "64ca0d34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.11276628077030182,\n",
       "  'token': 2908,\n",
       "  'token_str': 'gone',\n",
       "  'sequence': 'the sexy zebra is gone.'},\n",
       " {'score': 0.062051922082901,\n",
       "  'token': 2157,\n",
       "  'token_str': 'right',\n",
       "  'sequence': 'the sexy zebra is right.'},\n",
       " {'score': 0.04646315425634384,\n",
       "  'token': 2067,\n",
       "  'token_str': 'back',\n",
       "  'sequence': 'the sexy zebra is back.'},\n",
       " {'score': 0.03310095891356468,\n",
       "  'token': 2757,\n",
       "  'token_str': 'dead',\n",
       "  'sequence': 'the sexy zebra is dead.'},\n",
       " {'score': 0.02245509997010231,\n",
       "  'token': 2045,\n",
       "  'token_str': 'there',\n",
       "  'sequence': 'the sexy zebra is there.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_masker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "fill_masker(\"The sexy zebra is [MASK].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dd3e24dadaad47cbb10b23d096a4e613",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc09f72075854068aabbd977970f3c8f",
    "deepnote_cell_type": "image",
    "deepnote_img_src": "image-20250411-112956.png"
   },
   "source": [
    "<img src=\"image-20250411-112956.png\" width=\"\" align=\"\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8716b0c46de84cf58f892117ae1c7713",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "ranges": [],
      "toCodePoint": 36,
      "type": "link",
      "url": "https://arxiv.org/pdf/2304.04052.pdf"
     }
    ]
   },
   "source": [
    "https://arxiv.org/pdf/2304.04052.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "22ab57105b80443c83b4f7f915bd86ca",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a5f810df08924e47af7734905dc0d491",
    "deepnote_cell_type": "image",
    "deepnote_img_src": "image-20250411-113659.png"
   },
   "source": [
    "<img src=\"image-20250411-113659.png\" width=\"\" align=\"\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4b74a4a0beb74fae90b94c0c9e06a94e",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0f63ea1f8a5845a098c5210c742b5d1e",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 23,
      "type": "marks"
     }
    ]
   },
   "source": [
    "Distintos FINE TUNNING:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5777f76bf9df4f798197b9c2441545e0",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Token classification\n",
    "Identify each entity in a sentence, such as a person, location, or organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e1f9845a4adc4639a970cbd74223e572",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Extractive question answering\n",
    "Given a paragraph, answer a specific question and extract the answer from the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a6074b65026d43f291c721b8ea6c80bf",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Semantic search\n",
    "The features generated by the encoder can be handy to build a search system. Given a database of a hundred documents, we can compute the embeddings for each. Then, we can compare the input embeddings with the documents’ embeddings at inference time, hence identifying the most similar document in the database.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "8755cfbeae1e47c3b6f91111674d72ea",
    "deepnote_cell_type": "code",
    "execution_context_id": "c2e61181-37df-4a58-8c80-e5439fbf2f97",
    "execution_millis": 3541,
    "execution_start": 1744364452190,
    "source_hash": "5c88f518"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998536109924316}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    ")\n",
    "classifier(\"This movie is disgustingly good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "44ce805018aa4467bfc11e5c55beb0dc",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 144,
      "type": "marks"
     }
    ]
   },
   "source": [
    "some argue that fine-tuning might be unnecessary for most use cases. Instead, prompt engineering could be a more effective and cheaper approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=8d9183b8-669b-4ff8-8993-1e340ee425c9' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "9cf09acbe457448eb7e715ccf1e4d79a",
  "kernelspec": {
   "display_name": "AIGen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
